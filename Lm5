# VERSION 20 - REVISED WITH OVERFITTING FIXES

# Based on diagnostic results: Overfitting detected + Swap test failed

# SECTION 1 : Imports

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import KFold
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings(‘ignore’)
import copy

# SECTION 2 : Basic settings (UPDATED FOR LESS OVERFITTING)

SEQ_LENGTH = 50  # How many past steps to use
BATCH_SIZE = 32
LEARNING_RATE = 0.0005  # Reduced from 0.001
EPOCHS = 100
HIDDEN_SIZE = 32  # Reduced from 64
NUM_LAYERS = 1    # Reduced from 2
DROPOUT = 0.5     # Increased from 0.2
WEIGHT_DECAY = 0.01  # L2 regularization
NOISE_LEVEL = 0.01   # Input noise for regularization
PATIENCE = 10     # Early stopping patience

# SECTION 3 : Check device

device = torch.device(‘cuda’ if torch.cuda.is_available() else ‘cpu’)
print(f”Using device: {device}”)
print(f”Configuration: Hidden={HIDDEN_SIZE}, Layers={NUM_LAYERS}, Dropout={DROPOUT}”)

# SECTION 4 : Load data

df = pd.read_csv(‘swash_plate_pump_data (7).csv’)
flow_rate = df[‘Flow Rate (GPM)’].values
pressure = df[‘Pressure (PSI)’].values

print(f”Data loaded: {len(flow_rate)} samples”)

# SECTION 5 : Normalize data

scaler_X = StandardScaler()
scaler_y = StandardScaler()

flow_normalized = scaler_X.fit_transform(flow_rate.reshape(-1, 1)).flatten()
pressure_normalized = scaler_y.fit_transform(pressure.reshape(-1, 1)).flatten()

# Combine data

data = np.column_stack((flow_normalized, pressure_normalized))

# SECTION 6 : Create sequences with optional gap

def create_sequences(data, seq_length=50, stride=1, add_noise=False):
“”“Create sequences with optional noise augmentation”””
X, y = [], []
for i in range(0, len(data) - seq_length, stride):
X.append(data[i:i+seq_length, 0])  # Flow sequences
y.append(data[i+seq_length, 1])     # Next pressure value

```
X = np.array(X)
y = np.array(y)

# Optional: Add noise augmentation
if add_noise:
    X_noisy = X + np.random.normal(0, NOISE_LEVEL, X.shape)
    y_noisy = y + np.random.normal(0, NOISE_LEVEL/2, y.shape)
    X = np.vstack([X, X_noisy])
    y = np.hstack([y, y_noisy])
    print(f"Data augmented: {len(X)} sequences (doubled with noise)")

return X, y
```

# Create sequences (with augmentation for training)

X, y = create_sequences(data, SEQ_LENGTH, stride=1, add_noise=True)
print(f”Created {len(X)} sequences”)

# SECTION 7 : TIME-BASED SPLIT WITH GAP (CRITICAL FOR TIME SERIES)

# This prevents future data from leaking into training

GAP = 50  # Gap between train and validation to prevent temporal leakage

train_end = int(len(X) * 0.6)  # 60% for training
val_start = train_end + GAP     # Skip GAP samples
val_end = val_start + int(len(X) * 0.2)  # 20% for validation
test_start = val_end + GAP      # Another gap before test

# Ensure indices are within bounds

val_end = min(val_end, len(X) - GAP)
test_start = min(test_start, len(X))

X_train = X[:train_end]
y_train = y[:train_end]
X_val = X[val_start:val_end]
y_val = y[val_start:val_end]
X_test = X[test_start:] if test_start < len(X) else X[val_end:val_end+100]
y_test = y[test_start:] if test_start < len(y) else y[val_end:val_end+100]

print(f”\nTime-based split with gaps:”)
print(f”  Train: 0 to {train_end} ({len(X_train)} samples)”)
print(f”  Gap: {train_end} to {val_start} ({GAP} samples)”)
print(f”  Val: {val_start} to {val_end} ({len(X_val)} samples)”)
print(f”  Gap: {val_end} to {test_start} ({GAP} samples)”)
print(f”  Test: {test_start} to end ({len(X_test)} samples)”)

# Convert to tensors

X_train = torch.FloatTensor(X_train).to(device)
y_train = torch.FloatTensor(y_train).to(device)
X_val = torch.FloatTensor(X_val).to(device)
y_val = torch.FloatTensor(y_val).to(device)
X_test = torch.FloatTensor(X_test).to(device)
y_test = torch.FloatTensor(y_test).to(device)

# SECTION 8 : SIMPLIFIED LSTM MODEL WITH HEAVY REGULARIZATION

class LSTMModel(nn.Module):
def **init**(self, input_size=1, hidden_size=32, num_layers=1, dropout=0.5):
super(LSTMModel, self).**init**()

```
    # Simpler LSTM architecture
    self.lstm = nn.LSTM(input_size, hidden_size, num_layers, 
                       batch_first=True, dropout=0 if num_layers == 1 else dropout)
    
    # Batch normalization for stability
    self.batch_norm = nn.BatchNorm1d(hidden_size)
    
    # Dense layers with heavy dropout
    self.dropout1 = nn.Dropout(dropout)
    self.dense1 = nn.Linear(hidden_size, 16)  # Smaller intermediate layer
    self.relu = nn.ReLU()
    self.dropout2 = nn.Dropout(dropout * 0.8)  # Slightly less dropout in second layer
    self.dense2 = nn.Linear(16, 1)
    
    # Initialize weights properly
    self._init_weights()
    
def _init_weights(self):
    """Xavier initialization for better training stability"""
    for m in self.modules():
        if isinstance(m, nn.Linear):
            nn.init.xavier_uniform_(m.weight)
            if m.bias is not None:
                nn.init.constant_(m.bias, 0.01)
        elif isinstance(m, nn.LSTM):
            for param in m.parameters():
                if len(param.shape) >= 2:
                    nn.init.orthogonal_(param.data)
                else:
                    nn.init.normal_(param.data)

def forward(self, x):
    # Add input dimension if needed
    if len(x.shape) == 2:
        x = x.unsqueeze(-1)
    
    # LSTM processing
    lstm_out, _ = self.lstm(x)
    last_output = lstm_out[:, -1, :]
    
    # Batch normalization
    if last_output.shape[0] > 1:  # Only if batch size > 1
        last_output = self.batch_norm(last_output)
    
    # Dense layers with dropout
    x = self.dropout1(last_output)
    x = self.dense1(x)
    x = self.relu(x)
    x = self.dropout2(x)
    x = self.dense2(x)
    
    return x
```

# SECTION 9 : Initialize model

model = LSTMModel(input_size=1, hidden_size=HIDDEN_SIZE,
num_layers=NUM_LAYERS, dropout=DROPOUT).to(device)

print(f”\nModel architecture:”)
print(f”  Parameters: {sum(p.numel() for p in model.parameters()):,}”)

# SECTION 10 : ENHANCED TRAINING FUNCTION WITH REGULARIZATION

def train_model(model, X_train, y_train, X_val, y_val, epochs, batch_size):
criterion = nn.MSELoss()
# Adam with weight decay for L2 regularization
optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)

```
# More aggressive learning rate scheduling
scheduler = optim.lr_scheduler.ReduceLROnPlateau(
    optimizer, mode='min', patience=5, factor=0.5, min_lr=1e-6
)

train_losses = []
val_losses = []
best_val_loss = float('inf')
best_model_state = None
patience_counter = 0

for epoch in range(epochs):
    # Training phase
    model.train()
    epoch_loss = 0
    num_batches = 0
    
    # Shuffle data for each epoch
    indices = torch.randperm(len(X_train))
    X_shuffled = X_train[indices]
    y_shuffled = y_train[indices]
    
    # Process in batches
    for i in range(0, len(X_train), batch_size):
        batch_X = X_shuffled[i:i+batch_size]
        batch_y = y_shuffled[i:i+batch_size]
        
        # Skip if batch is too small (for batch norm)
        if len(batch_X) < 2:
            continue
        
        # Add noise during training for regularization
        if model.training and np.random.random() > 0.5:
            noise = torch.randn_like(batch_X) * NOISE_LEVEL
            batch_X = batch_X + noise
        
        # Add dimension for LSTM input
        batch_X = batch_X.unsqueeze(-1)
        
        optimizer.zero_grad()
        outputs = model(batch_X)
        
        # Add label smoothing (small noise to targets)
        if model.training:
            batch_y = batch_y + torch.randn_like(batch_y) * (NOISE_LEVEL / 2)
        
        loss = criterion(outputs.squeeze(), batch_y)
        loss.backward()
        
        # Gradient clipping to prevent exploding gradients
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        
        optimizer.step()
        
        epoch_loss += loss.item()
        num_batches += 1
    
    if num_batches == 0:
        continue
        
    avg_train_loss = epoch_loss / num_batches
    train_losses.append(avg_train_loss)
    
    # Validation phase
    model.eval()
    with torch.no_grad():
        X_val_input = X_val.unsqueeze(-1)
        val_outputs = model(X_val_input)
        val_loss = criterion(val_outputs.squeeze(), y_val)
        val_losses.append(val_loss.item())
    
    # Learning rate scheduling
    scheduler.step(val_loss)
    
    # Early stopping with best model tracking
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        best_model_state = copy.deepcopy(model.state_dict())
        patience_counter = 0
    else:
        patience_counter += 1
    
    if patience_counter >= PATIENCE:
        print(f"Early stopping triggered at epoch {epoch+1}")
        model.load_state_dict(best_model_state)
        break
    
    # Progress reporting
    if (epoch + 1) % 10 == 0:
        ratio = val_loss / avg_train_loss
        status = "OK" if ratio < 1.2 else "OVERFITTING!"
        current_lr = optimizer.param_groups[0]['lr']
        print(f"Epoch {epoch+1}/{epochs} - Train: {avg_train_loss:.6f}, "
              f"Val: {val_loss:.6f}, Ratio: {ratio:.3f} [{status}] LR: {current_lr:.6f}")

# Restore best model
if best_model_state is not None:
    model.load_state_dict(best_model_state)
    print(f"Restored best model from epoch with val loss: {best_val_loss:.6f}")

return train_losses, val_losses
```

# SECTION 11 : Train the model

print(”\nTraining model with regularization…”)
train_losses, val_losses = train_model(model, X_train, y_train, X_val, y_val,
epochs=EPOCHS, batch_size=BATCH_SIZE)

# SECTION 12 : Evaluate model

model.eval()

with torch.no_grad():
# Get predictions
X_test_input = X_test.unsqueeze(-1)
predictions = model(X_test_input).squeeze().cpu().numpy()
actuals = y_test.cpu().numpy()

```
# Also get train and val predictions for comparison
X_train_input = X_train.unsqueeze(-1)
X_val_input = X_val.unsqueeze(-1)
train_predictions = model(X_train_input).squeeze().cpu().numpy()
val_predictions = model(X_val_input).squeeze().cpu().numpy()
```

# Denormalize

predictions_orig = scaler_y.inverse_transform(predictions.reshape(-1, 1)).flatten()
actuals_orig = scaler_y.inverse_transform(actuals.reshape(-1, 1)).flatten()

# Calculate metrics

mse = np.mean((predictions - actuals) ** 2)
mae = np.mean(np.abs(predictions - actuals))

# Calculate R-squared for fidelity

ss_res = np.sum((actuals_orig - predictions_orig) ** 2)
ss_tot = np.sum((actuals_orig - np.mean(actuals_orig)) ** 2)
r2 = 1 - (ss_res / ss_tot) if ss_tot != 0 else 0
fidelity = r2 * 100

# Calculate overfitting metrics

train_mse = np.mean((train_predictions - y_train.cpu().numpy()) ** 2)
val_mse = np.mean((val_predictions - y_val.cpu().numpy()) ** 2)
overfitting_ratio = val_mse / train_mse if train_mse != 0 else float(‘inf’)

# SECTION 13 : Print results

print(”\n” + “=”*60)
print(“FINAL RESULTS”)
print(”=”*60)
print(f”Training MSE:    {train_mse:.6f}”)
print(f”Validation MSE:  {val_mse:.6f}”)
print(f”Test MSE:        {mse:.6f}”)
print(f”Test MAE:        {mae:.6f}”)
print(f”Fidelity Score:  {fidelity:.2f}%”)
print(f”R² Score:        {r2:.4f}”)
print(f”Overfitting Ratio: {overfitting_ratio:.3f}”)

if overfitting_ratio < 1.1:
print(“Status: ✓ EXCELLENT - No overfitting detected”)
elif overfitting_ratio < 1.2:
print(“Status: ✓ GOOD - Minimal overfitting”)
elif overfitting_ratio < 1.5:
print(“Status: ⚠ WARNING - Moderate overfitting”)
else:
print(“Status: ✗ SEVERE - Significant overfitting detected”)

# SECTION 14 : Enhanced Visualization

fig = plt.figure(figsize=(15, 12))

# Create a 3x2 grid

gs = fig.add_gridspec(3, 2, hspace=0.3, wspace=0.25)

# Plot 1: Training history with overfitting zones

ax1 = fig.add_subplot(gs[0, 0])
ax1.plot(train_losses, label=‘Train Loss’, alpha=0.7, linewidth=2)
ax1.plot(val_losses, label=‘Val Loss’, alpha=0.7, linewidth=2)
ax1.fill_between(range(len(train_losses)), 0, max(max(train_losses), max(val_losses)),
where=[v/t > 1.2 for v, t in zip(val_losses, train_losses)],
color=‘red’, alpha=0.1, label=‘Overfitting Zone’)
ax1.set_title(‘Training History’)
ax1.set_xlabel(‘Epoch’)
ax1.set_ylabel(‘Loss’)
ax1.legend()
ax1.grid(True, alpha=0.3)

# Plot 2: Overfitting ratio over time

ax2 = fig.add_subplot(gs[0, 1])
ratios = [v/t for v, t in zip(val_losses, train_losses)]
ax2.plot(ratios, alpha=0.7, linewidth=2, color=‘purple’)
ax2.axhline(y=1.0, color=‘green’, linestyle=’–’, alpha=0.5, label=‘Perfect (1.0)’)
ax2.axhline(y=1.2, color=‘orange’, linestyle=’–’, alpha=0.5, label=‘Threshold (1.2)’)
ax2.fill_between(range(len(ratios)), 1.0, ratios,
where=[r > 1.2 for r in ratios],
color=‘red’, alpha=0.2)
ax2.set_title(f’Overfitting Ratio (Final: {overfitting_ratio:.3f})’)
ax2.set_xlabel(‘Epoch’)
ax2.set_ylabel(‘Val/Train Loss Ratio’)
ax2.legend()
ax2.grid(True, alpha=0.3)

# Plot 3: Predictions vs Actuals (time series)

ax3 = fig.add_subplot(gs[1, :])
sample_size = min(300, len(predictions_orig))
x_axis = np.arange(sample_size)
ax3.plot(x_axis, actuals_orig[:sample_size], ‘b-’, label=‘Actual’, alpha=0.7, linewidth=1.5)
ax3.plot(x_axis, predictions_orig[:sample_size], ‘r-’, label=‘Predicted’, alpha=0.7, linewidth=1.5)
ax3.fill_between(x_axis, actuals_orig[:sample_size], predictions_orig[:sample_size],
alpha=0.2, color=‘gray’)
ax3.set_title(f’Pressure Predictions (R²: {r2:.4f})’)
ax3.set_xlabel(‘Test Sample’)
ax3.set_ylabel(‘Pressure (PSI)’)
ax3.legend()
ax3.grid(True, alpha=0.3)

# Plot 4: Scatter plot with regression line

ax4 = fig.add_subplot(gs[2, 0])
ax4.scatter(actuals_orig, predictions_orig, alpha=0.5, s=10, c=‘blue’)
min_val = min(actuals_orig.min(), predictions_orig.min())
max_val = max(actuals_orig.max(), predictions_orig.max())
ax4.plot([min_val, max_val], [min_val, max_val], ‘r–’, lw=2, label=‘Perfect Prediction’)

# Add regression line

z = np.polyfit(actuals_orig, predictions_orig, 1)
p = np.poly1d(z)
ax4.plot([min_val, max_val], p([min_val, max_val]), ‘g-’, alpha=0.5, label=f’Fit: y={z[0]:.2f}x+{z[1]:.2f}’)

ax4.set_title(f’Prediction Accuracy’)
ax4.set_xlabel(‘Actual Pressure (PSI)’)
ax4.set_ylabel(‘Predicted Pressure (PSI)’)
ax4.legend()
ax4.grid(True, alpha=0.3)

# Plot 5: Residuals distribution with normal curve

ax5 = fig.add_subplot(gs[2, 1])
residuals = actuals_orig - predictions_orig
n, bins, patches = ax5.hist(residuals, bins=30, edgecolor=‘black’, alpha=0.7, density=True)

# Fit normal distribution

mu, std = residuals.mean(), residuals.std()
xmin, xmax = ax5.get_xlim()
x = np.linspace(xmin, xmax, 100)
p = (1/np.sqrt(2*np.pi*std**2)) * np.exp(-(x-mu)**2/(2*std**2))
ax5.plot(x, p, ‘r-’, linewidth=2, label=f’Normal fit\nμ={mu:.3f}\nσ={std:.3f}’)

ax5.set_title(‘Residuals Distribution’)
ax5.set_xlabel(‘Residual (Actual - Predicted)’)
ax5.set_ylabel(‘Density’)
ax5.axvline(x=0, color=‘black’, linestyle=’–’, alpha=0.5)
ax5.legend()
ax5.grid(True, alpha=0.3)

plt.suptitle(‘Model Performance Analysis - Version 20’, fontsize=14, y=1.02)
plt.tight_layout()
plt.show()

print(”\n” + “=”*60)
print(“Training complete! Model is ready for deployment.”)
if overfitting_ratio > 1.2:
print(”\nNote: If overfitting persists, consider:”)
print(”  1. Using ensemble of models”)
print(”  2. Collecting more diverse training data”)
print(”  3. Further reducing model complexity”)
print(”  4. Increasing the gap between train/val splits”)
