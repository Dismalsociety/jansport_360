import torch
import torch.nn as nn
import matplotlib.pyplot as plt 
import pandas as pd 
import numpy as np
from sklearn.preprocessing import StandardScaler
from scipy.stats import pearsonr
import math

# Parameters
sequence_length = 10    
predict_length = 5     
batch_size = 32     
learning_rate = 0.0005  # Optimized for GRU
epochs = 100
dropout_rate = 0.3  
weight_decay = 5e-5  # Optimized for GRU
noise_std = 0.01  # Data augmentation

# Use GPU if available
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Load data
print("Loading data...")
df = pd.read_excel('generated_training_data_2.xlsx')
flow = df['FLow Rate'].values 
pressure = df['Pressure'].values 

# Combine features
data = np.column_stack([flow, pressure])

# Split data BEFORE creating sequences (prevents leakage)
total_samples = len(data)
train_size = int(0.7 * total_samples)  
val_size = int(0.15 * total_samples)   
test_size = total_samples - train_size - val_size  

train_data = data[:train_size]
val_data = data[train_size:train_size + val_size]
test_data = data[train_size + val_size:]

# Normalize using ONLY training data statistics
scaler = StandardScaler()
train_data_normalized = scaler.fit_transform(train_data)
val_data_normalized = scaler.transform(val_data)
test_data_normalized = scaler.transform(test_data)

# Create sequences function
def create_sequences(data_normalized, seq_len, pred_len):
    X_data = []
    Y_data = []
    for i in range(len(data_normalized) - seq_len - pred_len + 1):
        input_seq = data_normalized[i:i+seq_len]
        X_data.append(input_seq)
        target = data_normalized[i+seq_len:i+seq_len+pred_len, 1]
        Y_data.append(target)
    return np.array(X_data), np.array(Y_data)

# Create sequences for each set
X_train, Y_train = create_sequences(train_data_normalized, sequence_length, predict_length)
X_val, Y_val = create_sequences(val_data_normalized, sequence_length, predict_length)
X_test, Y_test = create_sequences(test_data_normalized, sequence_length, predict_length)

# Convert to tensors
X_train = torch.FloatTensor(X_train)
Y_train = torch.FloatTensor(Y_train)
X_val = torch.FloatTensor(X_val)
Y_val = torch.FloatTensor(Y_val)
X_test = torch.FloatTensor(X_test)
Y_test = torch.FloatTensor(Y_test)

print(f"Training samples: {len(X_train)}")
print(f"Validation samples: {len(X_val)}")
print(f"Test samples: {len(X_test)}")

# GRU Model Definition
class GRUModel(nn.Module):
    def __init__(self, input_size=2, hidden_size=48, output_size=5, dropout_rate=0.3):
        super(GRUModel, self).__init__()
        
        # Feature projection layer
        self.input_projection = nn.Linear(input_size, 32)
        self.relu = nn.ReLU()
        
        # GRU layer (simpler than LSTM, fewer parameters)
        self.gru = nn.GRU(
            input_size=32,
            hidden_size=hidden_size,
            num_layers=1,
            batch_first=True,
            dropout=0  # No dropout with single layer
        )
        
        # Output layers
        self.dropout = nn.Dropout(dropout_rate)
        self.output_layer = nn.Linear(hidden_size, output_size)
        
        # Layer normalization for stability
        self.layer_norm = nn.LayerNorm(hidden_size)
        
    def forward(self, x):
        # Project input features to higher dimension
        x = self.relu(self.input_projection(x))
        
        # GRU processing
        gru_out, hidden = self.gru(x)
        
        # Take the last hidden state
        last_hidden = hidden[-1]  # Shape: (batch, hidden_size)
        
        # Apply layer normalization
        x = self.layer_norm(last_hidden)
        
        # Apply dropout and output projection
        x = self.dropout(x)
        output = self.output_layer(x)
        
        return output

# Initialize model
model = GRUModel(
    input_size=2, 
    hidden_size=48, 
    output_size=predict_length, 
    dropout_rate=dropout_rate
).to(device)

# Count parameters
total_params = sum(p.numel() for p in model.parameters())
trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
print(f"\nModel Parameters:")
print(f"  Total: {total_params:,}")
print(f"  Trainable: {trainable_params:,}")

# Loss function and optimizer
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)

# Learning rate scheduler
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
    optimizer, 
    mode='min',
    factor=0.5,
    patience=10,
    verbose=True,
    min_lr=1e-6
)

# Early stopping
class EarlyStopping:
    def __init__(self, patience=15, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.best_loss = None
        self.early_stop = False
        
    def __call__(self, val_loss):
        if self.best_loss is None:
            self.best_loss = val_loss
        elif val_loss > self.best_loss - self.min_delta:
            self.counter += 1
            if self.counter >= self.patience:
                self.early_stop = True
        else:
            self.best_loss = val_loss
            self.counter = 0

early_stopping = EarlyStopping(patience=15)

# Training
print("\nTraining GRU model...")
train_losses = []
val_losses = []
learning_rates = []
best_model_state = None
best_val_loss = float('inf')

for epoch in range(epochs):
    # Training phase
    model.train()
    total_loss = 0
    num_batches = 0
    
    # Shuffle training data
    indices = torch.randperm(len(X_train))
    X_train_shuffled = X_train[indices]
    Y_train_shuffled = Y_train[indices]
    
    for i in range(0, len(X_train_shuffled), batch_size):
        batch_x = X_train_shuffled[i:i+batch_size].to(device)
        batch_y = Y_train_shuffled[i:i+batch_size].to(device)
        
        # Data augmentation: add noise during training
        if model.training:
            noise = torch.randn_like(batch_x) * noise_std
            batch_x = batch_x + noise
        
        # Forward pass
        outputs = model(batch_x)
        loss = criterion(outputs, batch_y)
        
        # Backward pass
        optimizer.zero_grad()
        loss.backward()
        
        # Gradient clipping
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        
        optimizer.step()
        
        total_loss += loss.item()
        num_batches += 1
    
    avg_train_loss = total_loss / num_batches
    train_losses.append(avg_train_loss)
    
    # Validation phase
    model.eval()
    with torch.no_grad():
        val_outputs = model(X_val.to(device))
        val_loss = criterion(val_outputs, Y_val.to(device))
        val_losses.append(val_loss.item())
    
    # Save best model
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        best_model_state = model.state_dict().copy()
    
    # Learning rate scheduling
    scheduler.step(val_loss)
    current_lr = optimizer.param_groups[0]['lr']
    learning_rates.append(current_lr)
    
    # Early stopping
    early_stopping(val_loss)
    
    # Print progress
    if (epoch + 1) % 10 == 0:
        print(f'Epoch {epoch+1}/{epochs}, Train Loss: {avg_train_loss:.4f}, '
              f'Val Loss: {val_loss:.4f}, LR: {current_lr:.6f}')
    
    if early_stopping.early_stop:
        print(f"Early stopping triggered at epoch {epoch+1}")
        break

# Load best model
if best_model_state is not None:
    model.load_state_dict(best_model_state)
    print(f"\nLoaded best model with validation loss: {best_val_loss:.4f}")

# Testing
print("\nEvaluating on test set...")
model.eval()

all_predictions = []
all_actuals = []

with torch.no_grad():
    for i in range(0, len(X_test), batch_size):
        batch_x = X_test[i:i+batch_size].to(device)
        batch_y = Y_test[i:i+batch_size]
        
        predictions = model(batch_x)
        
        all_predictions.append(predictions.cpu().numpy())
        all_actuals.append(batch_y.numpy())

# Concatenate results
if all_predictions:
    predictions = np.vstack(all_predictions)
    actuals = np.vstack(all_actuals)
    
    # Convert back to original scale
    pressure_mean = scaler.mean_[1]
    pressure_std = scaler.scale_[1]
    
    predictions_real = predictions * pressure_std + pressure_mean
    actuals_real = actuals * pressure_std + pressure_mean
    
    # Calculate metrics
    mse = np.mean((predictions_real - actuals_real) ** 2)
    rmse = np.sqrt(mse)
    mae = np.mean(np.abs(predictions_real - actuals_real))
    
    # Correlation and R-squared
    correlation, p_value = pearsonr(predictions_real.flatten(), actuals_real.flatten())
    ss_res = np.sum((actuals_real - predictions_real) ** 2)
    ss_tot = np.sum((actuals_real - np.mean(actuals_real)) ** 2)
    r_squared = 1 - (ss_res / ss_tot)
    
    print(f"\nTest Set Performance:")
    print(f"  MSE: {mse:.4f}")
    print(f"  RMSE: {rmse:.4f}")
    print(f"  MAE: {mae:.4f}")
    print(f"  Correlation: {correlation:.4f}")
    print(f"  R-squared: {r_squared:.4f}")
    
    # Generalization gap
    final_train_loss = train_losses[-1]
    final_val_loss = val_losses[-1]
    gap = final_val_loss - final_train_loss
    print(f"\nGeneralization Gap: {gap:.4f}")
    print(f"  Final Train Loss: {final_train_loss:.4f}")
    print(f"  Final Val Loss: {final_val_loss:.4f}")

# Plotting
plt.figure(figsize=(20, 5))

# Plot 1: Training vs Validation Loss
plt.subplot(1, 4, 1)
plt.plot(train_losses, label='Train Loss', alpha=0.8, linewidth=2)
plt.plot(val_losses, label='Val Loss', alpha=0.8, linewidth=2)
plt.title('Training vs Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True, alpha=0.3)

# Plot 2: Learning Rate Schedule
plt.subplot(1, 4, 2)
plt.plot(learning_rates, linewidth=2)
plt.title('Learning Rate Schedule')
plt.xlabel('Epoch')
plt.ylabel('Learning Rate')
plt.yscale('log')
plt.grid(True, alpha=0.3)

# Plot 3: Predictions vs Actual
if all_predictions:
    plt.subplot(1, 4, 3)
    sample_size = min(100, len(actuals_real))
    plt.plot(actuals_real[:sample_size, 0], label='Actual', alpha=0.7, linewidth=2)
    plt.plot(predictions_real[:sample_size, 0], label='Predicted', alpha=0.7, linewidth=2)
    plt.title('Test Set: First Pressure Step')
    plt.xlabel('Test Sample')
    plt.ylabel('Pressure (psiA)')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # Plot 4: Scatter Plot
    plt.subplot(1, 4, 4)
    plt.scatter(actuals_real.flatten(), predictions_real.flatten(), alpha=0.5, s=1)
    plt.plot([actuals_real.min(), actuals_real.max()], 
             [actuals_real.min(), actuals_real.max()], 
             'r--', label='Perfect Prediction', linewidth=2)
    plt.title(f'Actual vs Predicted (RÂ²={r_squared:.3f})')
    plt.xlabel('Actual Pressure')
    plt.ylabel('Predicted Pressure')
    plt.legend()
    plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print("\nTraining complete!")
