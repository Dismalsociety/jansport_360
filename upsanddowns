import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt


# Hyperparameters
SEQ_LENGTH = 10
BATCH_SIZE = 32
EPOCHS = 50
LR = 0.001
HIDDEN_SIZE = 64



# Load data from Excel
def load_data(filepath):
    df = pd.read_excel(filepath)
    df.columns = df.columns.str.strip()  # Remove spaces from start/end of each column name
    print("Cleaned column names:", list(df.columns))  # Debugging
    return df[['Flow Rate (gpm)']].values, df[['Predicted Pressure (psiA)']].values


# Dataset class
class FlowPressureDataset(Dataset):
   def __init__(self, flows, pressures, seq_length):
       self.X = []
       self.y = []
       for i in range(len(flows) - seq_length):
           self.X.append(flows[i:i+seq_length])
           self.y.append(pressures[i+seq_length])
       self.X = torch.tensor(self.X, dtype=torch.float32)
       self.y = torch.tensor(self.y, dtype=torch.float32)


   def __len__(self):
       return len(self.X)


   def __getitem__(self, idx):
       return self.X[idx], self.y[idx]


# Models
class FCNN(nn.Module):
   def __init__(self, input_size, hidden_size):
       super(FCNN, self).__init__()
       self.fc = nn.Sequential(
           nn.Flatten(),
           nn.Linear(input_size * SEQ_LENGTH, hidden_size),
           nn.ReLU(),
           nn.Linear(hidden_size, 1)
       )


   def forward(self, x):
       return self.fc(x)


class LSTMModel(nn.Module):
   def __init__(self, input_size, hidden_size):
       super(LSTMModel, self).__init__()
       self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)
       self.fc = nn.Linear(hidden_size, 1)


   def forward(self, x):
       _, (hn, _) = self.lstm(x)
       return self.fc(hn[-1])


class GRUModel(nn.Module):
   def __init__(self, input_size, hidden_size):
       super(GRUModel, self).__init__()
       self.gru = nn.GRU(input_size, hidden_size, batch_first=True)
       self.fc = nn.Linear(hidden_size, 1)


   def forward(self, x):
       _, hn = self.gru(x)
       return self.fc(hn[-1])


# Training function
def train_model(model, train_loader, criterion, optimizer):
   model.train()
   for epoch in range(EPOCHS):
       total_loss = 0
       for X_batch, y_batch in train_loader:
           optimizer.zero_grad()
           outputs = model(X_batch)
           loss = criterion(outputs, y_batch)
           loss.backward()
           optimizer.step()
           total_loss += loss.item()
       print(f'Epoch {epoch+1}/{EPOCHS}, Loss: {total_loss/len(train_loader):.4f}')


# Evaluation & plotting
def evaluate_model(model, flows, pressures, scaler_pressure, model_name):
   model.eval()
   X_test_seq = []
   y_true = []
   for i in range(len(flows) - SEQ_LENGTH):
       X_test_seq.append(flows[i:i+SEQ_LENGTH])
       y_true.append(pressures[i+SEQ_LENGTH])


   X_test_seq = torch.tensor(X_test_seq, dtype=torch.float32)
   y_true = torch.tensor(y_true, dtype=torch.float32)


   with torch.no_grad():
       y_pred = model(X_test_seq).numpy()


   y_true_inv = scaler_pressure.inverse_transform(y_true)
   y_pred_inv = scaler_pressure.inverse_transform(y_pred)


   # Plot
   plt.figure(figsize=(12, 4))
   plt.plot(y_true_inv, label='Actual Pressure', alpha=0.7)
   plt.plot(y_pred_inv, label='Predicted Pressure', alpha=0.7)
   plt.title(f'Actual vs. Predicted Pressure ({model_name})')
   plt.xlabel('Time Step')
   plt.ylabel('Pressure (psi)')
   plt.legend()
   plt.grid(True)
   plt.tight_layout()
   plt.savefig(f'{model_name}_pressure_plot.png')
   plt.show()


   # Metrics
   mse = np.mean((y_true_inv - y_pred_inv) ** 2)
   mae = np.mean(np.abs(y_true_inv - y_pred_inv))


   return mse, mae


# Main execution
def main(filepath):
   flows, pressures = load_data(filepath)


   # Normalize
   scaler_flow = MinMaxScaler()
   scaler_pressure = MinMaxScaler()
   flows = scaler_flow.fit_transform(flows)
   pressures = scaler_pressure.fit_transform(pressures)


   # Train-test split
   X_train, X_test, y_train, y_test = train_test_split(flows, pressures, test_size=0.2, shuffle=False)
   train_dataset = FlowPressureDataset(X_train, y_train, SEQ_LENGTH)
   train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)


   # Initialize models
   models = {
       'FCNN': FCNN(1, HIDDEN_SIZE),
       'LSTM': LSTMModel(1, HIDDEN_SIZE),
       'GRU': GRUModel(1, HIDDEN_SIZE),
   }


   results = []
   for name, model in models.items():
       print(f'\nTraining {name} model...')
       criterion = nn.MSELoss()
       optimizer = optim.Adam(model.parameters(), lr=LR)
       train_model(model, train_loader, criterion, optimizer)


       print(f'\nEvaluating {name} model...')
       mse, mae = evaluate_model(model, X_test, y_test, scaler_pressure, name)
       results.append({'Model': name, 'MSE': mse, 'MAE': mae})


   # Export metrics to Excel
   results_df = pd.DataFrame(results)
   results_df.to_excel('model_performance.xlsx', index=False)
   print("\nModel performance saved to 'model_performance.xlsx'")


# Call main directly
main('flow_rate_with_pressure - Copy (1).xlsx')  # Replace with your actual Excel filename
